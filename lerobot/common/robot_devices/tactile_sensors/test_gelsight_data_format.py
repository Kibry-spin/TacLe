#!/usr/bin/env python3
"""
GelSightæ•°æ®æ ¼å¼æµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†GelSightä¼ æ„Ÿå™¨çš„æ•°æ®æ ¼å¼ï¼ŒåŒ…æ‹¬ï¼š
1. ä¼ æ„Ÿå™¨æ•°æ®ç»“æ„
2. æ•°æ®å­—æ®µç±»å‹å’Œå¤§å°
3. ä¸LeRobotçš„é›†æˆæ ¼å¼
4. æ•°æ®ä¿å­˜å’Œè¯»å–ç¤ºä¾‹
"""

import sys
import time
import numpy as np
import torch
from pathlib import Path

# Add the project root to Python path
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

try:
    from lerobot.common.robot_devices.tactile_sensors.configs import GelSightConfig
    from lerobot.common.robot_devices.tactile_sensors.gelsight import GelSightSensor
except ImportError as e:
    print(f"Import error: {e}")
    print("Running in fallback mode...")
    sys.exit(1)


def test_data_format():
    """æµ‹è¯•GelSightæ•°æ®æ ¼å¼"""
    print("=== GelSight æ•°æ®æ ¼å¼æµ‹è¯• ===\n")
    
    # 1. åˆ›å»ºé…ç½®
    print("1. ä¼ æ„Ÿå™¨é…ç½®:")
    config = GelSightConfig(
        device_name="GelSight Mini",
        imgh=240,
        imgw=320,
        framerate=25
    )
    
    print(f"   è®¾å¤‡åç§°: {config.device_name}")
    print(f"   å›¾åƒå°ºå¯¸: {config.imgh} Ã— {config.imgw}")
    print(f"   å¸§ç‡: {config.framerate} fps")
    print(f"   é¢„æœŸæ•°æ®é‡: {config.imgh * config.imgw * 3 / 1024:.1f} KB/å¸§")
    
    # 2. åˆ›å»ºä¼ æ„Ÿå™¨ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    print("\n2. ä¼ æ„Ÿå™¨åˆ›å»º:")
    sensor = GelSightSensor(config)
    print(f"   ä¼ æ„Ÿå™¨ç±»å‹: {type(sensor).__name__}")
    print(f"   è¿æ¥çŠ¶æ€: {sensor.is_connected()}")
    
    # 3. æ¨¡æ‹Ÿæ•°æ®è¯»å–
    print("\n3. æ¨¡æ‹Ÿæ•°æ®æ ¼å¼:")
    
    # åˆ›å»ºæ¨¡æ‹Ÿå›¾åƒæ•°æ®
    mock_image = np.random.randint(0, 255, (config.imgh, config.imgw, 3), dtype=np.uint8)
    
    # æ¨¡æ‹Ÿä¼ æ„Ÿå™¨è¿”å›çš„æ•°æ®æ ¼å¼
    mock_data = {
        # LeRobotæ ‡å‡†å­—æ®µ
        'SN': config.device_name,
        'index': 12345,
        'sendTimestamp': time.time(),
        'recvTimestamp': time.time(),
        
        # GelSightç‰¹æœ‰å­—æ®µ
        'tactile_image': mock_image,
        'image_shape': mock_image.shape,
        
        # å‘åå…¼å®¹å­—æ®µ
        'timestamp': time.time(),
        'device_name': config.device_name,
        'frame_index': 12345,
        'image': mock_image,
        'sensor_config': {
            'imgh': config.imgh,
            'imgw': config.imgw,
            'framerate': config.framerate,
        }
    }
    
    print("   æ•°æ®å­—æ®µåˆ†æ:")
    total_size = 0
    for key, value in mock_data.items():
        if isinstance(value, np.ndarray):
            size_bytes = value.nbytes
            size_kb = size_bytes / 1024
            print(f"     {key:>15}: {value.shape} {value.dtype} = {size_bytes:,} bytes ({size_kb:.1f} KB)")
            total_size += size_bytes
        elif isinstance(value, (int, float)):
            size_bytes = 8  # ä¼°ç®—
            print(f"     {key:>15}: {type(value).__name__} = {size_bytes} bytes")
            total_size += size_bytes
        elif isinstance(value, str):
            size_bytes = len(value.encode('utf-8'))
            print(f"     {key:>15}: string = {size_bytes} bytes")
            total_size += size_bytes
        elif isinstance(value, dict):
            print(f"     {key:>15}: dict (é…ç½®ä¿¡æ¯)")
        else:
            print(f"     {key:>15}: {type(value).__name__}")
    
    print(f"\n   æ€»æ•°æ®é‡: {total_size:,} bytes ({total_size/1024:.1f} KB)")
    
    # 4. LeRobotæ ¼å¼è½¬æ¢
    print("\n4. LeRobotè§‚æµ‹æ ¼å¼:")
    sensor_name = "right_finger"
    
    # è½¬æ¢ä¸ºLeRobotè§‚æµ‹æ ¼å¼
    obs_dict = {}
    
    # åŸºæœ¬å…ƒæ•°æ®
    obs_dict[f"observation.tactile.{sensor_name}.sensor_sn"] = mock_data['SN']
    obs_dict[f"observation.tactile.{sensor_name}.frame_index"] = torch.tensor([mock_data['index']], dtype=torch.int64)
    obs_dict[f"observation.tactile.{sensor_name}.send_timestamp"] = torch.tensor([mock_data['sendTimestamp']], dtype=torch.float64)
    obs_dict[f"observation.tactile.{sensor_name}.recv_timestamp"] = torch.tensor([mock_data['recvTimestamp']], dtype=torch.float64)
    
    # å›¾åƒæ•°æ®
    obs_dict[f"observation.tactile.{sensor_name}.tactile_image"] = torch.from_numpy(mock_data['tactile_image'])
    
    print("   è§‚æµ‹å­—å…¸é”®å:")
    for key in obs_dict.keys():
        data = obs_dict[key]
        if hasattr(data, 'shape'):
            print(f"     {key}")
            print(f"       â””â”€ shape: {data.shape}, dtype: {data.dtype}")
        else:
            print(f"     {key}: {type(data).__name__} = '{data}'")
    
    return obs_dict


def test_data_analysis():
    """æ•°æ®åˆ†æç¤ºä¾‹"""
    print("\n=== æ•°æ®åˆ†æç¤ºä¾‹ ===\n")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    obs_dict = test_data_format()
    sensor_name = "right_finger"
    
    # æå–å›¾åƒæ•°æ®
    image_tensor = obs_dict[f"observation.tactile.{sensor_name}.tactile_image"]
    image_np = image_tensor.numpy()
    
    print("5. å›¾åƒæ•°æ®åˆ†æ:")
    print(f"   å½¢çŠ¶: {image_np.shape}")
    print(f"   æ•°æ®ç±»å‹: {image_np.dtype}")
    print(f"   æ•°å€¼èŒƒå›´: [{image_np.min()}, {image_np.max()}]")
    print(f"   å¹³å‡å€¼: {image_np.mean():.2f}")
    print(f"   æ ‡å‡†å·®: {image_np.std():.2f}")
    
    # é€šé“åˆ†æ
    print(f"\n   é€šé“åˆ†æ:")
    for i, channel in enumerate(['B', 'G', 'R']):
        channel_data = image_np[:, :, i]
        print(f"     {channel}é€šé“: å‡å€¼={channel_data.mean():.2f}, æ ‡å‡†å·®={channel_data.std():.2f}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n   ç»Ÿè®¡ä¿¡æ¯:")
    print(f"     åƒç´ æ€»æ•°: {image_np.size:,}")
    print(f"     éé›¶åƒç´ : {np.count_nonzero(image_np):,}")
    print(f"     å†…å­˜å ç”¨: {image_np.nbytes:,} bytes")


def test_storage_comparison():
    """å­˜å‚¨æ ¼å¼å¯¹æ¯”"""
    print("\n=== å­˜å‚¨æ ¼å¼å¯¹æ¯” ===\n")
    
    # ä¸åŒåˆ†è¾¨ç‡çš„æ•°æ®é‡å¯¹æ¯”
    configs = [
        ("ä½åˆ†è¾¨ç‡", 120, 160),
        ("æ ‡å‡†åˆ†è¾¨ç‡", 240, 320),
        ("é«˜åˆ†è¾¨ç‡", 480, 640),
    ]
    
    print("6. ä¸åŒåˆ†è¾¨ç‡æ•°æ®é‡å¯¹æ¯”:")
    print(f"   {'é…ç½®':^12} | {'å›¾åƒå°ºå¯¸':^12} | {'æ•°æ®é‡/å¸§':^12} | {'30fpsé€Ÿç‡':^12}")
    print(f"   {'-'*12}-+-{'-'*12}-+-{'-'*12}-+-{'-'*12}")
    
    for name, h, w in configs:
        size_bytes = h * w * 3  # uint8, 3é€šé“
        size_kb = size_bytes / 1024
        fps30_mb = size_bytes * 30 / (1024 * 1024)
        
        print(f"   {name:^12} | {h}Ã—{w:>6}   | {size_kb:>8.1f} KB | {fps30_mb:>8.1f} MB/s")
    
    # ä¸Tac3Då¯¹æ¯”
    print(f"\n7. ä¸Tac3Dä¼ æ„Ÿå™¨å¯¹æ¯”:")
    
    tac3d_size = (
        50 +        # sensor_sn
        8 +         # frame_index  
        8 +         # send_timestamp
        8 +         # recv_timestamp
        400 * 3 * 8 +   # positions_3d
        400 * 3 * 8 +   # displacements_3d
        400 * 3 * 8 +   # forces_3d
        3 * 8 +     # resultant_force
        3 * 8       # resultant_moment
    )
    
    gelsight_size = (
        20 +        # sensor_sn
        8 +         # frame_index
        8 +         # send_timestamp  
        8 +         # recv_timestamp
        240 * 320 * 3   # tactile_image
    )
    
    print(f"   Tac3Dæ•°æ®é‡:    {tac3d_size:,} bytes ({tac3d_size/1024:.1f} KB)")
    print(f"   GelSightæ•°æ®é‡: {gelsight_size:,} bytes ({gelsight_size/1024:.1f} KB)")
    print(f"   æ•°æ®é‡æ¯”ä¾‹:     {gelsight_size/tac3d_size:.1f}x")


def test_practical_usage():
    """å®é™…ä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== å®é™…ä½¿ç”¨ç¤ºä¾‹ ===\n")
    
    print("8. å®é™…é›†æˆç¤ºä¾‹ä»£ç :")
    
    # æ˜¾ç¤ºé…ç½®ç¤ºä¾‹
    config_example = """
# æœºå™¨äººé…ç½®ç¤ºä¾‹
config = AlohaRobotConfig(
    tactile_sensors={
        "right_finger": GelSightConfig(
            device_name="GelSight Mini",
            imgh=240,
            imgw=320,
            framerate=25,
        ),
        "left_finger": GelSightConfig(
            device_name="GelSight Mini 2", 
            imgh=240,
            imgw=320,
            framerate=25,
        ),
    }
)"""
    
    # æ˜¾ç¤ºæ•°æ®è¯»å–ç¤ºä¾‹
    data_access_example = """
# æ•°æ®è®¿é—®ç¤ºä¾‹
robot = ManipulatorRobot(config)
robot.connect()

obs = robot.capture_observation()

# è®¿é—®å³æ‰‹æŒ‡è§¦è§‰å›¾åƒ
right_image = obs["observation.tactile.right_finger.tactile_image"]
print(f"å³æŒ‡å›¾åƒ: {right_image.shape}")

# è®¿é—®å·¦æ‰‹æŒ‡è§¦è§‰å›¾åƒ  
left_image = obs["observation.tactile.left_finger.tactile_image"]
print(f"å·¦æŒ‡å›¾åƒ: {left_image.shape}")

# è·å–æ—¶é—´æˆ³
timestamp = obs["observation.tactile.right_finger.recv_timestamp"]
print(f"æ—¶é—´æˆ³: {timestamp.item()}")"""
    
    print("   é…ç½®ä»£ç :")
    for line in config_example.strip().split('\n'):
        print(f"     {line}")
        
    print("\n   æ•°æ®è®¿é—®ä»£ç :")
    for line in data_access_example.strip().split('\n'):
        print(f"     {line}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        test_data_format()
        test_data_analysis()
        test_storage_comparison()
        test_practical_usage()
        
        print(f"\nğŸ‰ GelSightæ•°æ®æ ¼å¼æµ‹è¯•å®Œæˆ!")
        
        print(f"\nğŸ“‹ æ€»ç»“:")
        print(f"  â€¢ æ•°æ®æ ¼å¼: å›¾åƒä¸ºä¸»çš„è§¦è§‰æ•°æ®")
        print(f"  â€¢ æ ‡å‡†å°ºå¯¸: 240Ã—320Ã—3 (~230KB/å¸§)")
        print(f"  â€¢ å…¼å®¹æ€§: å®Œå…¨å…¼å®¹LeRobotæ•°æ®é›†æ ¼å¼")
        print(f"  â€¢ æ‰©å±•æ€§: æ”¯æŒå¤šåˆ†è¾¨ç‡å’Œå¤šä¼ æ„Ÿå™¨é…ç½®")
        print(f"  â€¢ å¤„ç†æ–¹å¼: åŸºäºè®¡ç®—æœºè§†è§‰çš„å›¾åƒåˆ†æ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 