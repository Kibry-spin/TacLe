#!/usr/bin/env python3
"""
æµ‹è¯•GelSightæ•°æ®å¯è§†åŒ–åŠŸèƒ½

æœ¬è„šæœ¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„LeRobotæ•°æ®é›†ï¼ŒåŒ…å«GelSightè§¦è§‰æ•°æ®ï¼Œ
ç„¶åæµ‹è¯•visualize_dataset.pyè„šæœ¬çš„å¯è§†åŒ–åŠŸèƒ½ã€‚
"""

import sys
import tempfile
import time
from pathlib import Path

import numpy as np
import torch
import h5py
from PIL import Image

# Add the project root to Python path
sys.path.append(str(Path(__file__).parent))

def create_mock_gelsight_dataset():
    """åˆ›å»ºåŒ…å«GelSightæ•°æ®çš„æ¨¡æ‹Ÿæ•°æ®é›†"""
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = Path(tempfile.mkdtemp())
    dataset_dir = temp_dir / "test_gelsight_dataset"
    dataset_dir.mkdir(parents=True, exist_ok=True)
    
    # æ•°æ®é›†å‚æ•°
    num_episodes = 2
    episode_length = 10
    image_height, image_width = 240, 320
    
    print(f"åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†åœ¨: {dataset_dir}")
    
    # åˆ›å»ºæ•°æ®é›†å…ƒæ•°æ®
    meta_path = dataset_dir / "meta.json"
    meta_data = {
        "robot_type": "test_robot",
        "fps": 30,
        "video": False,
        "features": {
            "observation.tactile.left_gripper.tactile_image": {
                "dtype": "uint8",
                "shape": [image_height, image_width, 3],
                "names": ["height", "width", "channel"]
            },
            "observation.tactile.right_gripper.tactile_image": {
                "dtype": "uint8", 
                "shape": [image_height, image_width, 3],
                "names": ["height", "width", "channel"]
            },
            "observation.tactile.left_gripper.sensor_sn": {
                "dtype": "string",
                "shape": [],
                "names": []
            },
            "observation.tactile.right_gripper.sensor_sn": {
                "dtype": "string",
                "shape": [],
                "names": []
            },
            "observation.tactile.left_gripper.frame_index": {
                "dtype": "int64",
                "shape": [],
                "names": []
            },
            "observation.tactile.right_gripper.frame_index": {
                "dtype": "int64",
                "shape": [],
                "names": []
            },
            "observation.tactile.left_gripper.send_timestamp": {
                "dtype": "float64",
                "shape": [],
                "names": []
            },
            "observation.tactile.right_gripper.send_timestamp": {
                "dtype": "float64",
                "shape": [],
                "names": []
            },
            "observation.tactile.left_gripper.recv_timestamp": {
                "dtype": "float64",
                "shape": [],
                "names": []
            },
            "observation.tactile.right_gripper.recv_timestamp": {
                "dtype": "float64",
                "shape": [],
                "names": []
            },
            "action": {
                "dtype": "float32",
                "shape": [6],
                "names": ["joint_0", "joint_1", "joint_2", "joint_3", "joint_4", "joint_5"]
            },
            "observation.state": {
                "dtype": "float32",
                "shape": [6],
                "names": ["joint_0", "joint_1", "joint_2", "joint_3", "joint_4", "joint_5"]
            },
            "episode_index": {
                "dtype": "int64",
                "shape": [],
                "names": []
            },
            "frame_index": {
                "dtype": "int64",
                "shape": [],
                "names": []
            },
            "timestamp": {
                "dtype": "float64",
                "shape": [],
                "names": []
            },
            "next.done": {
                "dtype": "bool",
                "shape": [],
                "names": []
            },
            "next.reward": {
                "dtype": "float32",
                "shape": [],
                "names": []
            },
            "next.success": {
                "dtype": "bool",
                "shape": [],
                "names": []
            }
        },
        "total_episodes": num_episodes,
        "total_frames": num_episodes * episode_length,
        "camera_keys": [],  # æ²¡æœ‰ç›¸æœº
        "tactile_keys": [
            "observation.tactile.left_gripper.tactile_image",
            "observation.tactile.right_gripper.tactile_image"
        ]
    }
    
    import json
    with open(meta_path, 'w') as f:
        json.dump(meta_data, f, indent=2)
    
    # åˆ›å»ºå¿…éœ€çš„info.jsonæ–‡ä»¶
    meta_dir = dataset_dir / "meta"
    meta_dir.mkdir(exist_ok=True)
    
    info_path = meta_dir / "info.json"
    info_data = {
        "robot_type": "test_robot",
        "robot_name": "Test Robot for GelSight",
        "fps": 30,
        "video": False,
        "repo_tags": ["tactile", "gelsight", "test"],
        "license": "apache-2.0",
        "description": "Test dataset for GelSight tactile sensor visualization"
    }
    
    with open(info_path, 'w') as f:
        json.dump(info_data, f, indent=2)
    
    # åˆ›å»ºæ•°æ®æ–‡ä»¶
    data_path = dataset_dir / "data.hdf5"
    
    total_frames = num_episodes * episode_length
    
    with h5py.File(data_path, 'w') as f:
        # åˆ›å»ºæ•°æ®é›†
        
        # è§¦è§‰å›¾åƒæ•°æ®
        left_tactile_ds = f.create_dataset(
            "observation.tactile.left_gripper.tactile_image",
            (total_frames, image_height, image_width, 3),
            dtype=np.uint8
        )
        right_tactile_ds = f.create_dataset(
            "observation.tactile.right_gripper.tactile_image", 
            (total_frames, image_height, image_width, 3),
            dtype=np.uint8
        )
        
        # è§¦è§‰å…ƒæ•°æ®
        left_sn_ds = f.create_dataset(
            "observation.tactile.left_gripper.sensor_sn",
            (total_frames,),
            dtype=h5py.string_dtype()
        )
        right_sn_ds = f.create_dataset(
            "observation.tactile.right_gripper.sensor_sn",
            (total_frames,),
            dtype=h5py.string_dtype()
        )
        
        left_frame_ds = f.create_dataset(
            "observation.tactile.left_gripper.frame_index",
            (total_frames,),
            dtype=np.int64
        )
        right_frame_ds = f.create_dataset(
            "observation.tactile.right_gripper.frame_index",
            (total_frames,),
            dtype=np.int64
        )
        
        left_send_ts_ds = f.create_dataset(
            "observation.tactile.left_gripper.send_timestamp",
            (total_frames,),
            dtype=np.float64
        )
        right_send_ts_ds = f.create_dataset(
            "observation.tactile.right_gripper.send_timestamp",
            (total_frames,),
            dtype=np.float64
        )
        
        left_recv_ts_ds = f.create_dataset(
            "observation.tactile.left_gripper.recv_timestamp",
            (total_frames,),
            dtype=np.float64
        )
        right_recv_ts_ds = f.create_dataset(
            "observation.tactile.right_gripper.recv_timestamp",
            (total_frames,),
            dtype=np.float64
        )
        
        # å…¶ä»–å¿…éœ€æ•°æ®
        action_ds = f.create_dataset("action", (total_frames, 6), dtype=np.float32)
        state_ds = f.create_dataset("observation.state", (total_frames, 6), dtype=np.float32)
        episode_index_ds = f.create_dataset("episode_index", (total_frames,), dtype=np.int64)
        frame_index_ds = f.create_dataset("frame_index", (total_frames,), dtype=np.int64)
        timestamp_ds = f.create_dataset("timestamp", (total_frames,), dtype=np.float64)
        done_ds = f.create_dataset("next.done", (total_frames,), dtype=bool)
        reward_ds = f.create_dataset("next.reward", (total_frames,), dtype=np.float32)
        success_ds = f.create_dataset("next.success", (total_frames,), dtype=bool)
        
        # å¡«å……æ•°æ®
        frame_idx = 0
        for episode_idx in range(num_episodes):
            print(f"  ç”Ÿæˆepisode {episode_idx}")
            
            for step in range(episode_length):
                current_time = time.time() + frame_idx * 0.033  # 30fps
                
                # ç”Ÿæˆæ¨¡æ‹Ÿçš„è§¦è§‰å›¾åƒ
                # å·¦æ‰‹å›¾åƒ - æ¸å˜èƒŒæ™¯ + éšæœºå™ªå£°
                left_image = generate_tactile_image(
                    image_height, image_width, 
                    pattern="gradient", 
                    frame=frame_idx,
                    sensor="left"
                )
                
                # å³æ‰‹å›¾åƒ - åœ†å½¢æ¨¡å¼ + å‹åŠ›æ¨¡æ‹Ÿ
                right_image = generate_tactile_image(
                    image_height, image_width,
                    pattern="circle",
                    frame=frame_idx, 
                    sensor="right"
                )
                
                # å­˜å‚¨è§¦è§‰æ•°æ®
                left_tactile_ds[frame_idx] = left_image
                right_tactile_ds[frame_idx] = right_image
                
                # è§¦è§‰å…ƒæ•°æ®
                left_sn_ds[frame_idx] = "GelSight_Left_001"
                right_sn_ds[frame_idx] = "GelSight_Right_002"
                left_frame_ds[frame_idx] = frame_idx
                right_frame_ds[frame_idx] = frame_idx
                left_send_ts_ds[frame_idx] = current_time
                right_send_ts_ds[frame_idx] = current_time
                left_recv_ts_ds[frame_idx] = current_time + 0.001
                right_recv_ts_ds[frame_idx] = current_time + 0.001
                
                # å…¶ä»–æ•°æ®
                action_ds[frame_idx] = np.random.randn(6) * 0.1
                state_ds[frame_idx] = np.random.randn(6) * 0.1
                episode_index_ds[frame_idx] = episode_idx
                frame_index_ds[frame_idx] = frame_idx
                timestamp_ds[frame_idx] = current_time
                done_ds[frame_idx] = (step == episode_length - 1)
                reward_ds[frame_idx] = np.random.random()
                success_ds[frame_idx] = (step == episode_length - 1)
                
                frame_idx += 1
    
    print(f"âœ“ æ¨¡æ‹Ÿæ•°æ®é›†åˆ›å»ºå®Œæˆ: {dataset_dir}")
    return dataset_dir


def generate_tactile_image(height, width, pattern="gradient", frame=0, sensor="left"):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„è§¦è§‰å›¾åƒ"""
    
    image = np.zeros((height, width, 3), dtype=np.uint8)
    
    if pattern == "gradient":
        # æ¸å˜èƒŒæ™¯
        for i in range(height):
            for j in range(width):
                # åŸºäºä½ç½®çš„æ¸å˜
                r = int(255 * i / height)
                g = int(255 * j / width)
                b = int(255 * (i + j) / (height + width))
                
                # æ·»åŠ æ—¶é—´å˜åŒ–
                time_factor = np.sin(frame * 0.1) * 0.3 + 0.7
                
                image[i, j] = [
                    int(r * time_factor),
                    int(g * time_factor), 
                    int(b * time_factor)
                ]
    
    elif pattern == "circle":
        # åœ†å½¢å‹åŠ›æ¨¡å¼
        center_x, center_y = width // 2, height // 2
        radius = min(width, height) // 4
        
        for i in range(height):
            for j in range(width):
                # è·ç¦»ä¸­å¿ƒçš„è·ç¦»
                dist = np.sqrt((j - center_x) ** 2 + (i - center_y) ** 2)
                
                if dist < radius:
                    # åœ†å½¢å†…éƒ¨ï¼Œæ¨¡æ‹Ÿå‹åŠ›åˆ†å¸ƒ
                    pressure = 1.0 - (dist / radius)
                    
                    # æ—¶é—´å˜åŒ–çš„å‹åŠ›
                    time_pressure = np.sin(frame * 0.2) * 0.5 + 0.5
                    final_pressure = pressure * time_pressure
                    
                    image[i, j] = [
                        int(255 * final_pressure),
                        int(128 * final_pressure),
                        int(64 * final_pressure)
                    ]
                else:
                    # èƒŒæ™¯
                    image[i, j] = [50, 50, 50]
    
    # æ·»åŠ éšæœºå™ªå£°
    noise = np.random.randint(-20, 21, (height, width, 3))
    image = np.clip(image.astype(np.int32) + noise, 0, 255).astype(np.uint8)
    
    return image


def test_visualization(dataset_path):
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    print(f"\næµ‹è¯•å¯è§†åŒ–åŠŸèƒ½...")
    
    try:
        # å°è¯•åŠ è½½æ•°æ®é›†
        from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
        
        # ä½¿ç”¨rootå‚æ•°æŒ‡å®šæœ¬åœ°è·¯å¾„
        dataset = LeRobotDataset(repo_id="test_gelsight_dataset", root=str(dataset_path.parent))
        print(f"âœ“ æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"  æ€»episodes: {dataset.total_episodes}")
        print(f"  æ€»frames: {dataset.total_frames}")
        
        # æ£€æŸ¥è§¦è§‰keys
        if hasattr(dataset.meta, 'tactile_keys'):
            print(f"  è§¦è§‰keys: {dataset.meta.tactile_keys}")
        else:
            print(f"  è§¦è§‰keys: æœªå®šä¹‰")
        
        # æµ‹è¯•å•ä¸ªæ•°æ®ç‚¹
        sample = dataset[0]
        print(f"\nâœ“ æ•°æ®é‡‡æ ·æµ‹è¯•:")
        for key, value in sample.items():
            if "tactile" in key:
                if isinstance(value, torch.Tensor):
                    print(f"  {key}: {value.shape} {value.dtype}")
                else:
                    print(f"  {key}: {type(value)} {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ–¼ï¸  GelSightæ•°æ®å¯è§†åŒ–æµ‹è¯•")
    print("=" * 50)
    
    try:
        # 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†
        dataset_path = create_mock_gelsight_dataset()
        
        # 2. æµ‹è¯•æ•°æ®é›†åŠ è½½
        if not test_visualization(dataset_path):
            return 1
        
        # 3. æä¾›å¯è§†åŒ–å‘½ä»¤
        print(f"\nğŸ¯ æµ‹è¯•å¯è§†åŒ–å‘½ä»¤:")
        print(f"python lerobot/scripts/visualize_dataset.py \\")
        print(f"    --repo-id {dataset_path} \\")
        print(f"    --episode-index 0 \\")
        print(f"    --mode local")
        
        print(f"\nğŸ’¡ æœŸæœ›çœ‹åˆ°çš„å¯è§†åŒ–å†…å®¹:")
        print(f"  ğŸ“Š è§¦è§‰æ•°æ®:")
        print(f"    - tactile/left_gripper/tactile_image: æ¸å˜è§¦è§‰å›¾åƒ")
        print(f"    - tactile/right_gripper/tactile_image: åœ†å½¢å‹åŠ›å›¾åƒ") 
        print(f"    - tactile/*/image_stats/*: RGBé€šé“ç»Ÿè®¡")
        print(f"    - tactile/*/metadata/*: ä¼ æ„Ÿå™¨å…ƒæ•°æ®")
        
        print(f"\nğŸ“ æ•°æ®é›†ä½ç½®: {dataset_path}")
        print(f"âš ï¸  æ³¨æ„: è¿™æ˜¯ä¸´æ—¶æ•°æ®é›†ï¼Œç¨‹åºç»“æŸåä¼šè¢«æ¸…ç†")
        
        # 4. å¯é€‰ï¼šç›´æ¥è¿è¡Œå¯è§†åŒ–
        import argparse
        parser = argparse.ArgumentParser(add_help=False)
        parser.add_argument("--run-viz", action="store_true", help="ç›´æ¥è¿è¡Œå¯è§†åŒ–")
        args, _ = parser.parse_known_args()
        
        if args.run_viz:
            print(f"\nğŸš€ å¯åŠ¨å¯è§†åŒ–...")
            import subprocess
            
            cmd = [
                "python", "lerobot/scripts/visualize_dataset.py",
                "--repo-id", str(dataset_path),
                "--episode-index", "0",
                "--mode", "local"
            ]
            
            subprocess.run(cmd)
        else:
            print(f"\nğŸ’¡ æ·»åŠ  --run-viz å‚æ•°å¯ç›´æ¥è¿è¡Œå¯è§†åŒ–")
        
        return 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    import sys
    exit_code = main()
    sys.exit(exit_code) 