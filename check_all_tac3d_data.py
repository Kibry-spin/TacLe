#!/usr/bin/env python3
"""
å…¨é¢æ£€æŸ¥æ•°æ®é›†ä¸­æ‰€æœ‰Tac3Dæ•°æ®
åˆ†ææ•´ä¸ªæ•°æ®é›†çš„Tac3Dæ•°æ®åˆ†å¸ƒå’Œå˜åŒ–
"""

import sys
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, List
import matplotlib.pyplot as plt

# Add the project root to Python path
sys.path.append(str(Path(__file__).parent))

from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

def comprehensive_tac3d_analysis(dataset_path: str):
    """å…¨é¢åˆ†ææ‰€æœ‰Tac3Dæ•°æ®"""
    print("ğŸ” å¼€å§‹å…¨é¢æ£€æŸ¥Tac3Dæ•°æ®é›†...")
    print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print("=" * 80)
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = LeRobotDataset(dataset_path)
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)} ä¸ªæ ·æœ¬")
        print(f"Episodeæ•°é‡: {dataset.num_episodes}")
        print()
        
        # æ‰¾åˆ°æ‰€æœ‰Tac3Dæ•°æ®é”®
        sample = dataset[0]
        tac3d_keys = []
        force_keys = []
        moment_keys = []
        
        for key in sample.keys():
            if "tactile" in key and "tac3d" in key:
                tac3d_keys.append(key)
                if "resultant_force" in key:
                    force_keys.append(key)
                elif "resultant_moment" in key:
                    moment_keys.append(key)
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(tac3d_keys)} ä¸ªTac3Dæ•°æ®é”®")
        print(f"   å…¶ä¸­åˆåŠ›é”®: {len(force_keys)} ä¸ª")
        print(f"   åˆåŠ›çŸ©é”®: {len(moment_keys)} ä¸ª")
        print()
        
        if not tac3d_keys:
            print("âŒ æœªæ‰¾åˆ°Tac3Dæ•°æ®é”®")
            return
        
        # åˆ†ææ‰€æœ‰æ ·æœ¬çš„æ•°æ®
        print("ğŸ”„ åˆ†ææ‰€æœ‰æ ·æœ¬çš„Tac3Dæ•°æ®...")
        
        # ç»Ÿè®¡æ•°æ®
        stats = {
            'non_zero_samples': 0,           # éé›¶æ ·æœ¬æ•°é‡
            'total_samples': len(dataset),   # æ€»æ ·æœ¬æ•°
            'force_stats': {},               # åˆåŠ›ç»Ÿè®¡
            'moment_stats': {},              # åˆåŠ›çŸ©ç»Ÿè®¡
            'timestamp_stats': {},           # æ—¶é—´æˆ³ç»Ÿè®¡
            'force_history': [],             # åˆåŠ›å†å²æ•°æ®
            'moment_history': [],            # åˆåŠ›çŸ©å†å²æ•°æ®
            'non_zero_indices': [],          # éé›¶æ•°æ®çš„ç´¢å¼•
        }
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®ç»“æ„
        for key in force_keys:
            stats['force_stats'][key] = {
                'non_zero_count': 0,
                'max_magnitude': 0.0,
                'values': []
            }
        
        for key in moment_keys:
            stats['moment_stats'][key] = {
                'non_zero_count': 0,
                'max_magnitude': 0.0,
                'values': []
            }
        
        # éå†æ‰€æœ‰æ ·æœ¬
        print("æ­£åœ¨åˆ†ææ‰€æœ‰æ ·æœ¬...")
        for i in range(len(dataset)):
            if i % 50 == 0:
                print(f"  è¿›åº¦: {i}/{len(dataset)} ({i/len(dataset)*100:.1f}%)")
            
            sample = dataset[i]
            sample_has_non_zero = False
            
            # æ£€æŸ¥åˆåŠ›æ•°æ®
            for key in force_keys:
                force_data = sample[key]
                magnitude = torch.norm(force_data).item()
                stats['force_stats'][key]['values'].append(magnitude)
                
                if magnitude > 1e-6:  # éé›¶é˜ˆå€¼
                    stats['force_stats'][key]['non_zero_count'] += 1
                    stats['force_stats'][key]['max_magnitude'] = max(
                        stats['force_stats'][key]['max_magnitude'], magnitude
                    )
                    sample_has_non_zero = True
                    
                    # è®°å½•å…·ä½“æ•°å€¼
                    if magnitude > 0.001:  # è®°å½•æ˜¾è‘—éé›¶å€¼
                        stats['force_history'].append({
                            'index': i,
                            'key': key,
                            'force': force_data.numpy(),
                            'magnitude': magnitude
                        })
            
            # æ£€æŸ¥åˆåŠ›çŸ©æ•°æ®
            for key in moment_keys:
                moment_data = sample[key]
                magnitude = torch.norm(moment_data).item()
                stats['moment_stats'][key]['values'].append(magnitude)
                
                if magnitude > 1e-6:  # éé›¶é˜ˆå€¼
                    stats['moment_stats'][key]['non_zero_count'] += 1
                    stats['moment_stats'][key]['max_magnitude'] = max(
                        stats['moment_stats'][key]['max_magnitude'], magnitude
                    )
                    sample_has_non_zero = True
                    
                    # è®°å½•å…·ä½“æ•°å€¼
                    if magnitude > 0.001:  # è®°å½•æ˜¾è‘—éé›¶å€¼
                        stats['moment_history'].append({
                            'index': i,
                            'key': key,
                            'moment': moment_data.numpy(),
                            'magnitude': magnitude
                        })
            
            if sample_has_non_zero:
                stats['non_zero_samples'] += 1
                stats['non_zero_indices'].append(i)
        
        print(f"  åˆ†æå®Œæˆ: {len(dataset)}/{len(dataset)} (100.0%)")
        print()
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print("ğŸ“ˆ æ•°æ®ç»Ÿè®¡ç»“æœ:")
        print("-" * 60)
        print(f"æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"éé›¶æ ·æœ¬æ•°: {stats['non_zero_samples']}")
        print(f"éé›¶æ¯”ä¾‹: {stats['non_zero_samples']/stats['total_samples']*100:.2f}%")
        print()
        
        # åˆåŠ›ç»Ÿè®¡
        print("ğŸ”¸ åˆåŠ›æ•°æ®ç»Ÿè®¡:")
        for key, stat in stats['force_stats'].items():
            sensor_name = key.split('.')[-2] if '.' in key else 'unknown'
            print(f"  {sensor_name}:")
            print(f"    éé›¶æ ·æœ¬: {stat['non_zero_count']}/{stats['total_samples']} ({stat['non_zero_count']/stats['total_samples']*100:.2f}%)")
            print(f"    æœ€å¤§åŠ›å¤§å°: {stat['max_magnitude']:.6f} N")
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            values = np.array(stat['values'])
            if len(values) > 0:
                print(f"    å¹³å‡åŠ›å¤§å°: {np.mean(values):.6f} N")
                print(f"    æ ‡å‡†å·®: {np.std(values):.6f} N")
                print(f"    æ•°å€¼åˆ†å¸ƒ: min={np.min(values):.6f}, max={np.max(values):.6f}")
        print()
        
        # åˆåŠ›çŸ©ç»Ÿè®¡
        print("ğŸ”¸ åˆåŠ›çŸ©æ•°æ®ç»Ÿè®¡:")
        for key, stat in stats['moment_stats'].items():
            sensor_name = key.split('.')[-2] if '.' in key else 'unknown'
            print(f"  {sensor_name}:")
            print(f"    éé›¶æ ·æœ¬: {stat['non_zero_count']}/{stats['total_samples']} ({stat['non_zero_count']/stats['total_samples']*100:.2f}%)")
            print(f"    æœ€å¤§åŠ›çŸ©å¤§å°: {stat['max_magnitude']:.6f} NÂ·m")
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            values = np.array(stat['values'])
            if len(values) > 0:
                print(f"    å¹³å‡åŠ›çŸ©å¤§å°: {np.mean(values):.6f} NÂ·m")
                print(f"    æ ‡å‡†å·®: {np.std(values):.6f} NÂ·m")
                print(f"    æ•°å€¼åˆ†å¸ƒ: min={np.min(values):.6f}, max={np.max(values):.6f}")
        print()
        
        # æ˜¾ç¤ºéé›¶æ•°æ®è¯¦æƒ…
        if stats['force_history'] or stats['moment_history']:
            print("ğŸ¯ éé›¶æ•°æ®è¯¦æƒ…:")
            
            if stats['force_history']:
                print(f"  æ˜¾è‘—éé›¶åˆåŠ›æ•°æ® ({len(stats['force_history'])} ä¸ª):")
                for i, entry in enumerate(stats['force_history'][:10]):  # æ˜¾ç¤ºå‰10ä¸ª
                    sensor_name = entry['key'].split('.')[-2] if '.' in entry['key'] else 'unknown'
                    print(f"    {i+1:2d}. æ ·æœ¬{entry['index']:3d} {sensor_name}: {entry['force']} (å¤§å°: {entry['magnitude']:.6f})")
                if len(stats['force_history']) > 10:
                    print(f"    ... è¿˜æœ‰ {len(stats['force_history']) - 10} ä¸ªéé›¶åˆåŠ›æ•°æ®")
            
            if stats['moment_history']:
                print(f"  æ˜¾è‘—éé›¶åˆåŠ›çŸ©æ•°æ® ({len(stats['moment_history'])} ä¸ª):")
                for i, entry in enumerate(stats['moment_history'][:10]):  # æ˜¾ç¤ºå‰10ä¸ª
                    sensor_name = entry['key'].split('.')[-2] if '.' in entry['key'] else 'unknown'
                    print(f"    {i+1:2d}. æ ·æœ¬{entry['index']:3d} {sensor_name}: {entry['moment']} (å¤§å°: {entry['magnitude']:.6f})")
                if len(stats['moment_history']) > 10:
                    print(f"    ... è¿˜æœ‰ {len(stats['moment_history']) - 10} ä¸ªéé›¶åˆåŠ›çŸ©æ•°æ®")
        else:
            print("âŒ æœªå‘ç°ä»»ä½•æ˜¾è‘—çš„éé›¶è§¦è§‰æ•°æ®")
            print("å¯èƒ½çš„åŸå› :")
            print("  1. ä¼ æ„Ÿå™¨æœªä¸ç‰©ä½“æ¥è§¦")
            print("  2. ä¼ æ„Ÿå™¨æ ¡å‡†é—®é¢˜")
            print("  3. æ•°æ®é‡‡é›†é…ç½®é”™è¯¯")
            print("  4. ä¼ æ„Ÿå™¨ç¡¬ä»¶æ•…éšœ")
        
        # æ£€æŸ¥æ—¶é—´æˆ³æ•°æ®
        print("\nğŸ•’ æ—¶é—´æˆ³æ•°æ®æ£€æŸ¥:")
        timestamp_keys = [k for k in tac3d_keys if 'timestamp' in k]
        
        for key in timestamp_keys:
            timestamps = []
            for i in range(min(100, len(dataset))):  # æ£€æŸ¥å‰100ä¸ªæ ·æœ¬
                sample = dataset[i]
                ts = sample[key].item() if isinstance(sample[key], torch.Tensor) else sample[key]
                timestamps.append(ts)
            
            timestamps = np.array(timestamps)
            sensor_name = key.split('.')[-2] if '.' in key else 'unknown'
            field_name = key.split('.')[-1] if '.' in key else 'unknown'
            
            print(f"  {sensor_name} {field_name}:")
            print(f"    æ•°å€¼èŒƒå›´: [{np.min(timestamps):.6f}, {np.max(timestamps):.6f}]")
            print(f"    æ˜¯å¦å…¨ä¸ºé›¶: {'æ˜¯' if np.all(timestamps == 0) else 'å¦'}")
            if not np.all(timestamps == 0):
                print(f"    æ—¶é—´é—´éš”: {np.mean(np.diff(timestamps)):.6f} ç§’")
        
        # æ£€æŸ¥å…¶ä»–3Dæ•°æ®
        print("\nğŸ“Š 3Dæ•°æ®æ•°ç»„æ£€æŸ¥:")
        array_keys = [k for k in tac3d_keys if any(x in k for x in ['positions_3d', 'forces_3d', 'displacements_3d'])]
        
        for key in array_keys:
            field_name = key.split('.')[-1] if '.' in key else 'unknown'
            sensor_name = key.split('.')[-2] if '.' in key else 'unknown'
            
            # æ£€æŸ¥å‰10ä¸ªæ ·æœ¬
            non_zero_count = 0
            max_values = []
            
            for i in range(min(10, len(dataset))):
                sample = dataset[i]
                data = sample[key]
                if torch.any(data != 0):
                    non_zero_count += 1
                max_val = torch.max(torch.abs(data)).item()
                max_values.append(max_val)
            
            print(f"  {sensor_name} {field_name}:")
            print(f"    å½¢çŠ¶: {sample[key].shape}")
            print(f"    å‰10ä¸ªæ ·æœ¬ä¸­éé›¶æ ·æœ¬: {non_zero_count}/10")
            print(f"    æœ€å¤§ç»å¯¹å€¼: {np.max(max_values):.6f}")
            print(f"    æ˜¯å¦å…¨ä¸ºé›¶: {'æ˜¯' if np.max(max_values) == 0 else 'å¦'}")
        
        print(f"\nâœ… å…¨é¢æ•°æ®æ£€æŸ¥å®Œæˆ")
        
        # æ€»ç»“å’Œå»ºè®®
        print("\nğŸ¯ è¯Šæ–­æ€»ç»“:")
        if stats['non_zero_samples'] == 0:
            print("âŒ æ‰€æœ‰è§¦è§‰æ•°æ®éƒ½ä¸ºé›¶")
            print("ğŸ”§ å»ºè®®æ£€æŸ¥:")
            print("  1. ä¼ æ„Ÿå™¨è¿æ¥çŠ¶æ€")
            print("  2. ä¼ æ„Ÿå™¨æ ¡å‡†æ˜¯å¦æ­£ç¡®")
            print("  3. æ•°æ®é‡‡é›†æ—¶æ˜¯å¦æœ‰ç‰©ç†æ¥è§¦")
            print("  4. ä¼ æ„Ÿå™¨UDPé€šä¿¡æ˜¯å¦æ­£å¸¸")
        elif stats['non_zero_samples'] < stats['total_samples'] * 0.1:
            print("âš ï¸  å¤§éƒ¨åˆ†è§¦è§‰æ•°æ®ä¸ºé›¶")
            print("ğŸ”§ å¯èƒ½çš„é—®é¢˜:")
            print("  1. é—´æ­‡æ€§æ¥è§¦ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
            print("  2. ä¼ æ„Ÿå™¨çµæ•åº¦è®¾ç½®")
            print("  3. éƒ¨åˆ†æ—¶é—´æ®µæ— æ¥è§¦")
        else:
            print("âœ… è§¦è§‰æ•°æ®æ­£å¸¸ï¼ŒåŒ…å«æœ‰æ•ˆçš„æ¥è§¦ä¿¡æ¯")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def analyze_episode_patterns(dataset_path: str):
    """åˆ†æepisodeä¸­çš„æ•°æ®æ¨¡å¼"""
    print(f"\nğŸ¬ Episodeæ•°æ®æ¨¡å¼åˆ†æ...")
    
    try:
        dataset = LeRobotDataset(dataset_path)
        
        for episode_idx in range(min(3, dataset.num_episodes)):  # æœ€å¤šåˆ†æ3ä¸ªepisodes
            print(f"\nğŸ“Š Episode {episode_idx}:")
            
            from_idx = int(dataset.episode_data_index["from"][episode_idx].item())
            to_idx = int(dataset.episode_data_index["to"][episode_idx].item())
            
            print(f"  å¸§èŒƒå›´: {from_idx} - {to_idx-1} (å…± {to_idx-from_idx} å¸§)")
            
            # åˆ†ææ•´ä¸ªepisodeçš„forceæ•°æ®
            force_magnitudes = []
            for i in range(from_idx, to_idx):
                sample = dataset[i]
                for key in sample.keys():
                    if 'resultant_force' in key and 'tactile' in key:
                        force = sample[key]
                        magnitude = torch.norm(force).item()
                        force_magnitudes.append(magnitude)
                        break  # åªå–ç¬¬ä¸€ä¸ªforceé”®
            
            force_magnitudes = np.array(force_magnitudes)
            
            print(f"  åˆåŠ›å¤§å°ç»Ÿè®¡:")
            print(f"    å¹³å‡å€¼: {np.mean(force_magnitudes):.6f}")
            print(f"    æœ€å¤§å€¼: {np.max(force_magnitudes):.6f}")
            print(f"    éé›¶å¸§æ•°: {np.sum(force_magnitudes > 1e-6)}/{len(force_magnitudes)}")
            
            # æ‰¾åˆ°åŠ›å€¼å˜åŒ–çš„æ—¶é—´ç‚¹
            if np.any(force_magnitudes > 1e-6):
                non_zero_indices = np.where(force_magnitudes > 1e-6)[0]
                print(f"    é¦–æ¬¡éé›¶: å¸§ {non_zero_indices[0] + from_idx}")
                print(f"    æœ€åéé›¶: å¸§ {non_zero_indices[-1] + from_idx}")
                print(f"    æœ€å¤§åŠ›æ—¶åˆ»: å¸§ {np.argmax(force_magnitudes) + from_idx}")
            else:
                print(f"    âŒ æ•´ä¸ªepisodeæ— æœ‰æ•ˆåŠ›æ•°æ®")
    
    except Exception as e:
        print(f"âŒ Episodeåˆ†æå‡ºé”™: {e}")

if __name__ == "__main__":
    # ä½¿ç”¨å®Œæ•´è·¯å¾„
    dataset_path = "/home/user/.cache/huggingface/lerobot/user/test_two2"
    
    print(f"æ£€æŸ¥æ•°æ®é›†è·¯å¾„: {dataset_path}")
    
    if not Path(dataset_path).exists():
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        exit(1)
    
    # å…¨é¢åˆ†ææ•°æ®é›†
    comprehensive_tac3d_analysis(dataset_path)
    
    # åˆ†æepisodeæ¨¡å¼
    analyze_episode_patterns(dataset_path) 